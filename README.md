# Zephyr Platform

## DescriÃ§Ã£o

O **Zephyr Platformr** Ã© um projeto focado em comparar duas abordagens para consumir e persistir dados de um arquivo `.csv`: utilizando um serviÃ§o consumidor tradicional e usando o **Kafka Connect**.

Este projeto inclui um `docker-compose.yml` que define e configura um ambiente baseado em contÃªineres com **Kafka**, **PostgreSQL** e **Kafka Connect**, facilitando a inicializaÃ§Ã£o e a orquestraÃ§Ã£o dos serviÃ§os necessÃ¡rios para o processamento de mensagens e persistÃªncia de dados.

---

## ğŸ“Œ Infraestrutura e ServiÃ§os

### 1. PostgreSQL (`postgres`)
- Banco de dados relacional para armazenamento de dados.
- PersistÃªncia garantida atravÃ©s do volume `pgdata`.
- Exposto na porta **5432**.

### 2. Zookeeper (`zookeeper`)
- ServiÃ§o de coordenaÃ§Ã£o necessÃ¡rio para o funcionamento do Kafka.
- Exposto na porta **2181**.

### 3. Kafka (`kafka`)
- Broker de mensagens usado para publicar e consumir eventos.
- Configurado para escutar nas portas **9092** (externa) e **9093** (interna para comunicaÃ§Ã£o entre contÃªineres).
- Permite a criaÃ§Ã£o automÃ¡tica de tÃ³picos.

### 4. Kafka Connect (`kafka-connect`)
- Framework para integrar Kafka com bancos de dados e outros sistemas.
- Conectado ao broker Kafka (`kafka:9093`).
- ExpÃµe sua API REST na porta **8083**.
- Configurado para armazenar informaÃ§Ãµes de configuraÃ§Ã£o, offsets e status em tÃ³picos internos.
- Plugins e conectores podem ser adicionados no diretÃ³rio `./connect-plugins`.

### ğŸŒ Rede e PersistÃªncia
- Todos os serviÃ§os fazem parte da rede Docker chamada `minha_rede`, garantindo a comunicaÃ§Ã£o entre os contÃªineres.
- O uso de volumes garante persistÃªncia dos dados do PostgreSQL.
- O ambiente permite aplicaÃ§Ãµes com processamento assÃ­ncrono e integraÃ§Ã£o de dados entre diferentes sistemas, usando **Kafka** como middleware de mensagens.

---

## âš™ï¸ ConfiguraÃ§Ã£o do Conector Sink (`sink-config.json`)

### PostgreSQL Sink Connector
Este projeto utiliza o **Kafka Connect** com o **JDBC Sink Connector** para armazenar dados do Kafka em um banco **PostgreSQL**.

### ConfiguraÃ§Ã£o do Conector:
- **TÃ³pico de origem**: `topic.csv.kafka`
- **Banco de destino**: PostgreSQL (`kafkateste`)
- **Tabela**: `product` (criada automaticamente se nÃ£o existir)
- **Modo de inserÃ§Ã£o**: `insert` (apenas insere novos registros)
- **ConversÃ£o de dados**: JSON

### ğŸš€ Como Registrar o Conector
1. Certifique-se de que o **Kafka Connect** estÃ¡ rodando.
2. Envie a configuraÃ§Ã£o via API REST do Kafka Connect:
   ```bash
   curl -X POST -H "Content-Type: application/json" --data @sink-config.json http://localhost:8083/connectors
   ```
3. Monitore o status do conector:
   ```bash
   curl -X GET http://localhost:8083/connectors/postgres-sink-connector/status
   ```

Esse conector facilita a ingestÃ£o contÃ­nua de dados do Kafka para o PostgreSQL, garantindo escalabilidade e compatibilidade com JSON. ğŸš€

---

## â˜• ServiÃ§os Java

Os serviÃ§os Java foram desenvolvidos com **Java 17**, utilizando **Maven** para automaÃ§Ã£o de build.

- **ServiÃ§o Produtor**:
  - LÃª um arquivo CSV da pasta configurada.
  - Envia os dados para um tÃ³pico correspondente ao tipo de processamento desejado:
    - **CONSUMER**: Envia um lote de mensagens comprimidas para que o serviÃ§o consumidor receba, descomprima, leia e persista os dados.
    - **KAFKA**: Ajusta a mensagem conforme a configuraÃ§Ã£o do **Kafka Connect** e do `sink-config.json`, permitindo persistÃªncia direta no banco.

---

## ğŸ›  Como Iniciar o Projeto

### ğŸ“Œ PrÃ©-requisitos
- **Java 17**
- **Docker**
- **Maven**
- **Postman** (ou outra ferramenta para enviar requisiÃ§Ãµes HTTP)

### ğŸš€ Passos para ConfiguraÃ§Ã£o
1. Configure o ambiente do Java corretamente.
2. Ajuste o arquivo `sink-config.json` conforme necessÃ¡rio.
3. Configure os arquivos `application.properties` ou `application.yml` dos serviÃ§os Java.
4. Importe a collection de requisiÃ§Ãµes que estÃ¡ na pasta `config` do Postman.
5. Suba os dois serviÃ§os Java (produtor e consumidor).
6. ApÃ³s tudo estar configurado corretamente, envie as requisiÃ§Ãµes via Postman.
7. **Importante**: Substitua o caminho na request do Postman pelo caminho real das pastas de CSV:
   - `small/` para um teste com **10 linhas**.
   - `large/` para um teste com **1 milhÃ£o de linhas**.

---

## ğŸ” Comandos Ãšteis para AnÃ¡lise

### ğŸ“Š Verificar se um tÃ³pico tem mensagens acumuladas:
```bash
docker exec -it kafka kafka-run-class kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic {NOME_DO_TOPICO} --time -1
```
**Resposta esperada:**
```
{NOME_DO_TOPICO}:0:0
```

### ğŸ“œ Listar tÃ³picos disponÃ­veis:
```bash
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092
```

### ğŸ“¥ Ler uma mensagem do tÃ³pico:
```bash
docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic {NOME_DO_TOPICO} --from-beginning --max-messages 1 --property print.value=true
```

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a **MIT**. Sinta-se livre para usar, modificar e contribuir!

---

## ğŸ“« Contato
Caso tenha alguma dÃºvida ou sugestÃ£o, entre em contato via [GitHub Issues](https://github.com/marcuslira2/zephyr-stream-processor/issues).

